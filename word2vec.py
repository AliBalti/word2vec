# -*- coding: utf-8 -*-
"""Word2Vec.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QAfNXoP5wfqnnTiO9nWFJdoV5uuVgkfh
"""

import kagglehub

# Download latest version
path = kagglehub.dataset_download("saurabhbadole/game-of-thrones-book-dataset")

print("Path to dataset files:", path)

pip install gensim

import nltk
nltk.download('punkt')
nltk.download('punkt_tab')  # <-- Newer versions of NLTK require this too

import pandas as pd
import os
import numpy as np
import gensim
from nltk import sent_tokenize
from gensim.utils import simple_preprocess

data_path = os.path.join(path, "1 - A Game of Thrones.txt")
with open(data_path, 'r', encoding='utf-8') as f:
    text = f.read()

print(text[:500])  # preview first 500 characters

story = []
raw_sent = sent_tokenize(text)
for sent in raw_sent:
    story.append(simple_preprocess(sent))

story

from gensim.models import Word2Vec

model = Word2Vec(
    vector_size=10,        # number of features per word (was default 100)
    window=10,              # context window size
  #  min_count=2,            # ignore rare words
    sg=0,                   # 1 = Skip-gram; 0 = CBOW (Skip-gram works better for rare words)

)

model.build_vocab(story)

model.train(story, total_examples=model.corpus_count, epochs=5)

model.wv.most_similar('robb')

"""story"""

model.wv['jon']

y = model.wv.index_to_key

y

from sklearn.decomposition import PCA

pca = PCA(n_components=3)

X = pca.fit_transform(model.wv.get_normed_vectors())

X.shape

import plotly.express as px
fig = px.scatter_3d(X[200:300],x=0,y=1,z=2, color=y[200:300])
fig.show()